#!/bin/bash
# ============================================================================
# VOSTOK-1 :: LLM Setup Script
# Configura o Ollama com modelo Qwen 2.5 para anÃ¡lise de sentimento
# ============================================================================

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘           VOSTOK-1 :: LLM ENGINE SETUP                      â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

CONTAINER_NAME="vostok_llm"
MODEL_NAME="qwen2.5:7b-instruct"

# ============================================================================
# STEP 1: Verificar container
# ============================================================================
echo "ğŸ” Verificando container LLM Engine..."

if ! docker ps --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
    echo "âŒ Container '${CONTAINER_NAME}' nÃ£o estÃ¡ rodando!"
    echo ""
    echo "Execute primeiro:"
    echo "  docker compose up -d llm_engine"
    exit 1
fi

echo "âœ… Container '${CONTAINER_NAME}' estÃ¡ rodando"
echo ""

# ============================================================================
# STEP 2: Pull do modelo Qwen
# ============================================================================
echo "ğŸ§  Baixando modelo ${MODEL_NAME}..."
echo "   (Isso pode levar alguns minutos na primeira vez)"
echo ""

docker exec -it ${CONTAINER_NAME} ollama pull ${MODEL_NAME}

echo ""
echo "âœ… Modelo ${MODEL_NAME} instalado!"
echo ""

# ============================================================================
# STEP 3: Teste do modelo
# ============================================================================
echo "ğŸ§ª Testando modelo com pergunta simples..."
echo ""

TEST_RESPONSE=$(docker exec ${CONTAINER_NAME} ollama run ${MODEL_NAME} "Hello, are you ready? Reply in one sentence." 2>/dev/null)

if [ -n "$TEST_RESPONSE" ]; then
    echo "ğŸ“ Resposta do modelo:"
    echo "   \"${TEST_RESPONSE}\""
    echo ""
    echo "âœ… Modelo funcionando corretamente!"
else
    echo "âš ï¸  Modelo nÃ£o respondeu. Verifique os logs:"
    echo "   docker logs ${CONTAINER_NAME}"
fi

# ============================================================================
# STEP 4: Listar modelos instalados
# ============================================================================
echo ""
echo "ğŸ“‹ Modelos instalados:"
docker exec ${CONTAINER_NAME} ollama list

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘                    SETUP CONCLUÃDO!                         â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "API disponÃ­vel em: http://localhost:11434"
echo ""
echo "Testar via API:"
echo '  curl http://localhost:11434/api/generate -d '"'"'{"model":"qwen2.5:7b-instruct","prompt":"BTC sentiment?"}'\'
echo ""
